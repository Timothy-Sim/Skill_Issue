import psycopg2
from psycopg2.extras import execute_values, RealDictCursor
from datetime import datetime
import json

# --- FUNCTIONS FOR matches.py (Ingestion) ---

def get_user_by_username(cur, username):
    try:
        cur.execute("SELECT id FROM users WHERE chess_com_username = %s", (username,))
        user_row = cur.fetchone()
        if user_row:
            return user_row[0]
        else:
            print(f"Error: User '{username}' not found in 'users' table.")
            return None
    except (Exception, psycopg2.DatabaseError) as error:
        print(f"Error fetching user: {error}")
        return None

def insert_game(cur, user_id, source, source_game_id, game_url, pgn_data, game_date):
    insert_game_sql = """
    INSERT INTO games (user_id, source, source_game_id, game_url, pgn_data, game_date)
    VALUES (%s, %s, %s, %s, %s, %s)
    ON CONFLICT (user_id, source, source_game_id) DO NOTHING
    RETURNING id;
    """
    try:
        cur.execute(insert_game_sql, (
            user_id, source, source_game_id, game_url, pgn_data, game_date
        ))
        game_id_row = cur.fetchone()
        
        if game_id_row:
            return game_id_row[0]
        else:
            print(f"Game {source_game_id} already exists in DB. Skipping.")
            return None
    except (Exception, psycopg2.DatabaseError) as error:
        print(f"Error inserting game: {error}")
        return None

def batch_insert_mistakes(cur, mistakes_list_of_dicts):
    if not mistakes_list_of_dicts:
        print("No mistakes to insert.")
        return

    columns = [
        'game_id', 'move_number', 'player_color', 'prior_fen', 'move_made', 'best_move',
        'cpl', 'mistake_type', 'mistake_category', 'game_phase', 'material_balance', 
        'board_complexity', 'king_self_safety', 'king_opponent_status', 
        'castling_status_self', 'piece_moved', 'move_type', 'piece_was_attacked', 
        'piece_was_defended', 'piece_was_defending', 'piece_was_pinned'
    ]
    
    values_list = [tuple(mistake.get(col) for col in columns) for mistake in mistakes_list_of_dicts]
    insert_mistakes_sql = f"INSERT INTO mistakes ({', '.join(columns)}) VALUES %s;"
    
    try:
        execute_values(cur, insert_mistakes_sql, values_list)
        print(f"Successfully batch-inserted {len(values_list)} mistakes.")
    except (Exception, psycopg2.DatabaseError) as error:
        print(f"Error batch-inserting mistakes: {error}")

# --- FUNCTIONS FOR analysis.py (v9 Pipeline) ---

def clear_old_habits_and_feedback(cur, user_id):
    """
    Deletes all existing habits and feedback for a user before
    re-analyzing them. Also unlinks all mistakes.
    """
    try:
        print(f"Clearing old analysis data for user {user_id}...")
        
        # 1. Unlink all mistakes from habits
        cur.execute(
            """
            UPDATE mistakes SET habit_id = NULL 
            WHERE game_id IN (SELECT id FROM games WHERE user_id = %s)
            """, 
            (user_id,)
        )
        
        # 2. Deleting from 'habits' will CASCADE and delete from 'feedback'
        cur.execute("DELETE FROM habits WHERE user_id = %s", (user_id,))
        print("Old analysis cleared.")
    except (Exception, psycopg2.DatabaseError) as error:
        print(f"Error clearing old habits: {error}")
        raise # Raise the error to stop the transaction

def get_all_mistakes_for_user_v6(cur, user_id):
    """
    Fetches ALL mistakes for a user, regardless of habit_id.
    This is the main dataset for HDBSCAN.
    """
    sql = """
    SELECT 
        id, cpl, move_number, -- Numeric features
        mistake_type, mistake_category, game_phase, material_balance, -- Categorical features
        board_complexity, king_self_safety, king_opponent_status, 
        castling_status_self, piece_moved, move_type, piece_was_attacked, 
        piece_was_defended, piece_was_defending, piece_was_pinned
    FROM mistakes
    WHERE game_id IN (SELECT id FROM games WHERE user_id = %s);
    """
    try:
        with cur.connection.cursor(cursor_factory=RealDictCursor) as dict_cur:
            dict_cur.execute(sql, (user_id,))
            mistakes = dict_cur.fetchall()
        print(f"Fetched {len(mistakes)} total mistakes for user {user_id} for clustering.")
        return [dict(row) for row in mistakes]
    except (Exception, psycopg2.DatabaseError) as error:
        print(f"Error fetching all mistakes: {error}")
        return []

def link_mistakes_to_habit(cur, new_serial_habit_id, list_of_mistake_ids):
    """
    Updates the 'habit_id' for a list of mistakes.
    This is called *after* a new habit is created.
    """
    if not list_of_mistake_ids:
        print("No mistake IDs to link.")
        return

    # Create a list of tuples: (new_serial_habit_id, mistake_id)
    data_to_update = [(new_serial_habit_id, mistake_id) for mistake_id in list_of_mistake_ids]

    update_sql = """
    UPDATE mistakes AS m
    SET habit_id = data.habit_id
    FROM (VALUES %s) AS data(habit_id, mistake_id)
    WHERE m.id = data.mistake_id;
    """
    
    try:
        execute_values(cur, update_sql, data_to_update)
        print(f"Linked {len(list_of_mistake_ids)} mistakes to new habit_id {new_serial_habit_id}.")
    except (Exception, psycopg2.DatabaseError) as error:
        print(f"Error linking mistakes to habit: {error}")
        # This will rollback the transaction in main_analysis_pipeline

def save_habit_analysis(cur, user_id, hdbscan_cluster_id, habit_name, triggers, confidence, prime_example_id, feedback_text):
    """
    Saves the results of the analysis to the 'habits' and 'feedback' tables.
    Returns the new 'habit' table ID (the serial key).
    """
    try:
        # --- 1. Save to 'habits' table ---
        habit_sql = """
        INSERT INTO habits (user_id, habit_name, description)
        VALUES (%s, %s, %s)
        RETURNING id;
        """
        description = f"HDBSCAN Cluster {hdbscan_cluster_id} ({confidence * 100:.0f}% confidence)"
        cur.execute(habit_sql, (user_id, habit_name, description))
        new_serial_habit_id = cur.fetchone()[0]

        # --- 2. Save to 'feedback' table ---
        feedback_sql = """
        INSERT INTO feedback (habit_id, feedback_text, triggers_json, prime_example_mistake_id)
        VALUES (%s, %s, %s, %s)
        """
        triggers_json = json.dumps(triggers)
        cur.execute(feedback_sql, (new_serial_habit_id, feedback_text, triggers_json, prime_example_id))
        
        print(f"Saved analysis for new habit {new_serial_habit_id} (Cluster {hdbscan_cluster_id}).")
        return new_serial_habit_id # Return the *database* ID
        
    except (Exception, psycopg2.DatabaseError) as error:
        print(f"Error saving habit analysis: {error}")
        return None